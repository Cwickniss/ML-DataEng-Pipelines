{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://towardsdatascience.com/scikit-learn-pipeline-tutorial-with-parameter-tuning-and-cross-validation-e5b8280c01fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/bank-full.csv', sep=';')\n",
    "target = data.pop('y')\n",
    "target = target.map({'yes': 1, 'no':0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask for categorical columns\n",
    "categorical_mask = (data.dtypes=='object')\n",
    "# get a list of categorical columns\n",
    "categorical_columns = data.columns[categorical_mask].tolist()\n",
    "# get a list of numeric columns\n",
    "num_cols = data.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "# columns to apply OrdinalEncoder on.\n",
    "oe_cols = [c for c in categorical_columns if data[c].nunique()>5]\n",
    "# columns to apply OneHotEncoder on.\n",
    "ohe_cols = [c for c in categorical_columns if data[c].nunique()<=5]\n",
    "len(oe_cols), len(ohe_cols), len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare encoders and Imputer\n",
    "ohe_unique_list = [data[c].unique().tolist() for c in ohe_cols]\n",
    "oe_unique_list = [data[c].unique().tolist() for c in oe_cols]\n",
    "ohe = OneHotEncoder(categories=ohe_unique_list)\n",
    "oe = OrdinalEncoder(categories=oe_unique_list)\n",
    "imp = SimpleImputer(strategy='constant', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put them all in a make_column_transformer\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html\n",
    "preprocess = make_column_transformer(\n",
    "    (oe, oe_cols),\n",
    "    (ohe, ohe_cols),\n",
    "    (imp, num_cols),\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Pipeline with Preprocessing, Learner and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html\n",
    "# Compute the ANOVA F-value for the provided sample.\n",
    "fs = SelectKBest(score_func=f_classif, k=5)\n",
    "#selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "steps = [\n",
    "    ('preprocess', preprocess),\n",
    "    ('select', fs),\n",
    "    ('clf', estimator)\n",
    "]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Pipeline\n",
    "Now, It’s as simple as any other machine learning algorithm, we first fit and then use predict. Predict function does all other preprocessing and then applies the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "#y_pred = pipeline.predict(X_test)\n",
    "y_pred = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "pred_df = pd.DataFrame({'y': y_test,'y_pred': y_pred})\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__max_depth': np.arange(3,10,1),\n",
    "    'clf__n_estimators': np.arange(50,250,50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_auc = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=5, scoring='roc_auc', cv=5, verbose=False)\n",
    "rand_auc.fit(X_train, y_train)\n",
    "print(rand_auc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rand_auc.predict_proba(X_test)[:,1]\n",
    "pred_df = pd.DataFrame({'y': y_test,'y_pred': y_pred})\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Multiple Classifiers (See How Easy it is!)\n",
    "Takes a couple of minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),    \n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    steps = [\n",
    "        ('preprocess', preprocess),\n",
    "        ('select', fs),\n",
    "        ('clf', classifier)\n",
    "    ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    pipeline.fit(X_train, y_train)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, using scikit-learn’s Pipeline feature helps a lot in streamlining machine learning workflow and makes a data scientist's job easier and can focus their time on fine-tuning models, rather than doing data pre-processing steps repetitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
